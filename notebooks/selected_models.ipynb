{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df782e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"zhao\"\n",
    "metric = \"auroc_scores\"\n",
    "naive_models = [\"InDegreeTargetSorter\", \"OutDegreeSourceSorter\", \"CorrelationDecoder\", \"HarmonicDegreeSorter\"]\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "p = api.project('GRN_inference', entity='scialdonelab')\n",
    "sweeps = p.sweeps()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1406331",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected = {\n",
    "    \"GATv2Conv + MLPDecoder\": {'mplayer': 'GATv2Conv', 'decoder': 'MLPDecoder', 'encoder': 'GNNEncoder'}, \n",
    "    \"GCNConv + MLPDecoder\": {'mplayer': 'GCNConv', 'decoder': 'MLPDecoder', 'encoder': 'GNNEncoder'}, \n",
    "    \"GCNConv + InnerProductDecoder\": {'mplayer': 'GCNConv', 'decoder': 'InnerProductDecoder', 'encoder': 'GNNEncoder'},\n",
    "    \"GCNConv only\": {'mplayer': 'GCNConv', 'decoder': 'MLPDecoder', 'encoder': 'GNNGraphOnlyEncoder'},\n",
    "}\n",
    "\n",
    "def get_top_runs(sweep, n):\n",
    "    runs = sweep.runs\n",
    "    runs = [run for run in runs if run.state == \"finished\"]\n",
    "    first_runs = sorted(runs, key=lambda run: run.summary.get(\"_timestamp\", 0), reverse=False)[:250]\n",
    "    top_runs = sorted(first_runs, key=lambda run: run.summary.get(\"val_average_precision_score\", 0), reverse=True)[:n]\n",
    "    return top_runs\n",
    "\n",
    "sweep_top = {}\n",
    "for sweep in sweeps:\n",
    "    sweep = api.sweep(f\"scialdonelab/GRN_inference/{sweep.id}\")\n",
    "    if sweep.config[\"parameters\"][\"dataset\"]['value'] == dataset and sweep.config[\"parameters\"][\"negative_sampling\"]['value'] in [\"random\", \"structured_tail\", \"degree_aware\"]:\n",
    "        sweep_encoder = sweep.config[\"parameters\"][\"encoder\"]['value']\n",
    "        if sweep_encoder == 'GAE_Encoder':\n",
    "            sweep_encoder = 'GNNEncoder'\n",
    "        sweep_model = {\n",
    "            'mplayer': sweep.config[\"parameters\"][\"mplayer\"]['value'],\n",
    "            'decoder': sweep.config[\"parameters\"][\"decoder\"]['value'],\n",
    "            'encoder': sweep_encoder\n",
    "        }\n",
    "        if any(model == sweep_model for model in models_selected.values()):\n",
    "            id_string = f\"{sweep_model['decoder']}_{sweep_model['mplayer']}_{sweep_model['encoder']}_{sweep.config['parameters']['negative_sampling']['value']}\"\n",
    "            top_run = get_top_runs(sweep, n=1)\n",
    "            if id_string not in sweep_top:\n",
    "                sweep_top[id_string] = top_run[0]\n",
    "                sweep_top[f\"{id_string}_n_runs\"] = len(sweep.runs)\n",
    "            else:\n",
    "                prev_n_runs = sweep_top.get(f\"{id_string}_n_runs\", 0)\n",
    "                cur_n_runs = len(sweep.runs)\n",
    "                if cur_n_runs > prev_n_runs:\n",
    "                    sweep_top[id_string] = top_run[0]\n",
    "                    sweep_top[f\"{id_string}_n_runs\"] = cur_n_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494a68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: InnerProductDecoder_GCNConv_GNNEncoder_degree_aware, Run ID: df54ey1e\n",
      "Model: InnerProductDecoder_GCNConv_GNNEncoder_random, Run ID: njl162p1\n",
      "Model: InnerProductDecoder_GCNConv_GNNEncoder_structured_tail, Run ID: 00mdnkwn\n",
      "Model: MLPDecoder_GATv2Conv_GNNEncoder_degree_aware, Run ID: 53spb369\n",
      "Model: MLPDecoder_GATv2Conv_GNNEncoder_random, Run ID: zgy49z99\n",
      "Model: MLPDecoder_GATv2Conv_GNNEncoder_structured_tail, Run ID: gzxy5164\n",
      "Model: MLPDecoder_GCNConv_GNNEncoder_degree_aware, Run ID: 4rvc133w\n",
      "Model: MLPDecoder_GCNConv_GNNEncoder_random, Run ID: w64aad0a\n",
      "Model: MLPDecoder_GCNConv_GNNEncoder_structured_tail, Run ID: 91111gr1\n",
      "Model: MLPDecoder_GCNConv_GNNGraphOnlyEncoder_degree_aware, Run ID: ypm5rzod\n",
      "Model: MLPDecoder_GCNConv_GNNGraphOnlyEncoder_random, Run ID: s4khp2rv\n",
      "Model: MLPDecoder_GCNConv_GNNGraphOnlyEncoder_structured_tail, Run ID: 38qxu1ve\n",
      "IDs ['df54ey1e', 'njl162p1', '00mdnkwn', '53spb369', 'zgy49z99', 'gzxy5164', '4rvc133w', 'w64aad0a', '91111gr1', 'ypm5rzod', 's4khp2rv', '38qxu1ve']\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(sweep_top):\n",
    "    if not key.endswith('_n_runs'):\n",
    "        run = sweep_top[key]\n",
    "        print(f\"Model: {key}, Run ID: {run.id}\")\n",
    "\n",
    "run_ids = []\n",
    "for key in sorted(sweep_top):\n",
    "    if not key.endswith('_n_runs'):\n",
    "        run = sweep_top[key]\n",
    "        run_ids.append(run.id)\n",
    "print(\"IDs\",run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_run(decoder, sampling):\n",
    "    runs = api.runs(\n",
    "        f\"scialdonelab/GRN_inference\", \n",
    "        filters={\"config.model\": \"NaiveModel\", \"group\": None}, \n",
    "        order = \"+created_at\"\n",
    "    )\n",
    "    run = [\n",
    "        run for run in runs \n",
    "        if run.config.get(\"decoder\") == decoder \n",
    "        and run.config.get(\"negative_sampling\") == sampling\n",
    "        and run.config.get(\"dataset\") == dataset\n",
    "    ][0]\n",
    "    return run\n",
    "\n",
    "naive_runs = {}\n",
    "for decoder in naive_models:\n",
    "    for sampling in [\"random\", \"structured_tail\", \"degree_aware\"]:\n",
    "        run = get_naive_run(decoder, sampling)\n",
    "        naive_runs[f\"{decoder}_{sampling}\"] = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c37226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: yn3onvws, Model: CorrelationDecoder_degree_aware\n",
      "Run ID: 9653b013, Model: CorrelationDecoder_random\n",
      "Run ID: hnuaaieq, Model: CorrelationDecoder_structured_tail\n",
      "Run ID: n5r24sba, Model: HarmonicDegreeSorter_degree_aware\n",
      "Run ID: cf0g5o3z, Model: HarmonicDegreeSorter_random\n",
      "Run ID: 4p6z3ofx, Model: HarmonicDegreeSorter_structured_tail\n",
      "Run ID: ulqvoni1, Model: InDegreeTargetSorter_degree_aware\n",
      "Run ID: ivk0ydr6, Model: InDegreeTargetSorter_random\n",
      "Run ID: 9uqudp73, Model: InDegreeTargetSorter_structured_tail\n",
      "Run ID: 3kiybyyz, Model: OutDegreeSourceSorter_degree_aware\n",
      "Run ID: kyuvtba8, Model: OutDegreeSourceSorter_random\n",
      "Run ID: irpza8dz, Model: OutDegreeSourceSorter_structured_tail\n",
      "Naive run ids: ['ivk0ydr6', '9uqudp73', 'ulqvoni1', 'kyuvtba8', 'irpza8dz', '3kiybyyz', '9653b013', 'hnuaaieq', 'yn3onvws', 'cf0g5o3z', '4p6z3ofx', 'n5r24sba']\n"
     ]
    }
   ],
   "source": [
    "run_idstrings = []\n",
    "for run_id, run in naive_runs.items():\n",
    "    decoder = run.config.get('decoder', '')\n",
    "    sampling = run.config.get('negative_sampling', '')\n",
    "    id_string = f\"{decoder}_{sampling}\"\n",
    "    run_idstrings.append((id_string, run))\n",
    "\n",
    "for id_string, run in sorted(run_idstrings, key=lambda x: x[0]):\n",
    "    print(f\"Run ID: {run.id}, Model: {id_string}\")\n",
    "    \n",
    "naive_run_ids = [run.id for run in naive_runs.values()]\n",
    "print(\"Naive run ids:\", naive_run_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
